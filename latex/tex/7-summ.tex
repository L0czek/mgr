\cleardoublepage
\section{Summary} \label{chap:summ}
The topic of fuzz testing inside an embedded operating system is very complex and requires connecting together many components. In this thesis, I have shown how such setup can be established using open-source components such as \textit{AFLplusplus} \textit{fuzzer} and \textit{QEMU} system emulator. They were modified to fit the task of \textit{fuzzing} operating systems instead of simple applications. Additionally, a module conducting test case decoding was designed to enable structured \textit{fuzzing}. Thanks to this the created solution can be applied to an arbitrary target consisting of a set of functions and structs. Naturally, since this thesis aims at systems created using \textit{Rust} programming language, the target needs to expose an interface in \textit{Rust}. To achieve the support of such interfaces a special declarative language was designed. It allows for describing the target interface so that the compiler automatically generates the testing code which can call functions, create and manage objects. This generated code can be configured by the test case generated in \textit{AFLplusplus} \textit{fuzzer}. During runtime, it interprets the raw bytes sequence provided by the genetic algorithm inside \textit{AFL} to call the functions and methods inside the target.

The setup was evaluated by comparing the speed and effectiveness of \textit{fuzzing} a specially crafted target with services running under \textit{OPTEE} operating system. The experiments were constructed to show how different design choices impact the \textit{fuzzing} result. First and foremost, the issue of saving and restoring the state of the virtual machine during \textit{fuzzing} was investigated. Naturally, the first choice is whether to even implement the state preserving mechanism into \textit{QEMU}, as it doesn't come without cons. The experiments show that it heavily impacts the \textit{fuzzing} speed by adding significant delays due to the need to basically duplicate the memory and virtual processor state and then write it back. This slow down is not constant and may vary based on the target's architecture, for example, a small system employing only real time cores with limited resources will require far less time when compared to a system running \textit{Linux} operating system with $GB$ of RAM memory. However, preserving the initial state of the target operating system has one big advantage. It substantially increases the reproducibility of the registered crashes as there is no accumulation of changes done to the system across test cases. The results show that the slowdown resulted from the state restoring mechanism decreases the \textit{fuzzing} speed by almost two orders of magnitude. In this context, by \textit{fuzzing} speed I refer to the number of test cases the \textit{fuzzer} is able to execute per second. Additionally, the custom serialization method described in section \ref{sec:qemu_cus} appeared to be functioning more efficiently to the native one described in \ref{sec:qemu_nat} by gathering more crashes over the same time interval.

Next, the test case decoder from chapter \ref{chap:envir} was evaluated to see if it improves the exploration of the target leading to registering more crashes. This test plugged the binary test case generated by \textit{AFL} directly to the target. Of course, the \textit{fuzzed} services were designed in a way to allow passing in raw data. The results were then compared to another experiment where the \textit{fuzzer} ran using the same initial corpus but with the test case decoder enabled. The experiment revealed that the structured approach collected significantly more valuable test cases over the same time interval. This improvement is caused by the need to learn the data format used by the target. When the test case decoder is used, the structure of the data is provided by the target's description. On the other hand, the direct approach requires the genetic algorithm to learn how to construct the objects using primitive mutation operators which drastically decreases \textit{fuzzing} efficiency. Naturally, this approach is not ideal as it always generates proper function calls so, it might not find all bugs in code which interprets the raw data in the beginning of the handler. Nevertheless, this approach is still valuable as it can quickly explore the deeper layers.

The last test checked how seeding the \textit{fuzzer's} corpus with valuable data affects the process. To accomplish this I created a utility which allows for tracing unit tests and generating the binary test cases. This experiment checks whether the fuzzer whose corpus was seeded with unit tests managed to find more bugs to the randomly seeded one. The results show that, in the same time interval, the correctly seeded \textit{fuzzer} was able to trigger crashes which the randomly seeded one wasn't. Naturally, seeding the corpus with valuable elements allows the genetic algorithm inside \textit{AFL} to start exploring the search space from more meaningful points. This greatly increases the overall \textit{fuzzing} efficiency and allows locating bugs that can be hard to trigger by, for example, requiring some arithmetic condition to be met. In such cases a good suit of unit tests will help the process of fuzzing.

In conclusion, this thesis presents a robust setup allowing for fuzz testing arbitrary services on embedded platforms. I show how this system can be assembled from modified open-source components and repurposed to the task of \textit{fuzzing} operating system. Next, I evaluated many design choices that can be made during the construction of a similar project to chose what is best suited for the presented task. Unfortunately, as the described approach relies on heuristics and genetic algorithms it is not guaranteed to be the perfect solution for any case. Nonetheless, the discussed method provides ideas that can be useful when the target doesn't support any other \textit{fuzzing} method and just exposes some function like interface.